---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am Yangle Liu, an undergraduate student at the University of Liverpool. My research spans computer vision/graphics and machine learning, with interests in real-time scene understanding and editing, high-fidelity rendering, and data-driven methods for robust visual computing.

I am supervised by [Prof. Jieming Ma](https://scholar.xjtlu.edu.cn/en/persons/JiemingMa) at Xi‚Äôan Jiaotong‚ÄìLiverpool University (XJTLU) and [Prof. Dominik Wojtczak](https://www.csc.liv.ac.uk/~dominik/) at the University of Liverpool. In addition, I have actively collaborated with several international researchers with Prof. [Prof. Hai-Ning Liang](https://cma.hkust-gz.edu.cn/people/hai-ning-liang/) (HKUST (Guangzhou)), [Prof. Yaochun Shen](https://www.liverpool.ac.uk/people/yaochun-shen) (University of Liverpool), and [Postdoc. Bo Xiong](https://boxiong.io/) (Stanford University), with whom I maintain close academic collaboration.


# üî• News
- *2025.08*: &nbsp;üéâüéâ My collaborative paper will be presented as an Oral Presentation at BDAI, 2025! 
- *2024.11*: &nbsp;üéâüéâ The first collaborative paper I worked on was accepted by ICSTIS, 2024!

# üìù Publications 
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arXiv preprint</div><img src='/images/fruit.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CountingFruit: Real-Time 3D Fruit Counting with Language-Guided Semantic Gaussian Splatting](https://arxiv.org/abs/2506.01109)


Fengze Li, **Yangle Liu**, Jieming Ma*, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu 

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><div class="badge">BDAI 2025</div><img src='/images/seed.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](https://arxiv.org/abs/2506.20167)

<span style="color:red">(Oral Presentation)</span>

Fengze Li, Yue Wang, **Yangle Liu**, Dou Hong, Jieming Ma*, Huangxiang Li 

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>




<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM TMCCA 2024</div><img src='/images/EAST.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

EAST: Environment-Aware Stylized Transition Along the Reality-Virtuality Continuum

*Under Review*

Xiaohan Zhang, Kan Liu, **Yangle Liu**, Fangze Li, Jieming Ma and Yue Li* 

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>





<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICSTIS 2024</div><img src='/images/car.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Automated Generation of Parking Data Sets for Underground Car Parks](https://doi.org/10.4271/2025-01-7191)


Jiakai Li, **Yangle Liu**, Zheng Rong

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>



# üéñ Honors and Awards

- *2023* RoboMaster 2023 Master Super Competition: First Prize (Regional), Second Prize (National) 
- *2023* College Student Information System Innovation Competition: Outstanding Award
- *2023* Campus Technology Innovation Association: Managed 3D Modeling Project
- *2022* Campus Ambassador for XJTLU: Achieved promotional targets with six schools, received Pioneer Award 

# üìñ Educations
- *2024.09 - now*, Undergraduate, University of Liverpool, UK.
- *2022.09 - 2024.06*, Undergraduate, Xi‚Äôan Jiaotong‚ÄìLiverpool University, Suzhou.



# üíª Internships
<div class='paper-box'><div class='paper-box-image'><div><img src='/images/Neurova.jpg' alt="sym" style="width:150px; height:100px; object-fit:cover;"></div></div>
<div class='paper-box-text' markdown="1">

Neurova, New York

Machine Learning Intern 

*2025.06 - 2025.08*

</div>
</div>



<div class='paper-box'><div class='paper-box-image'><div><img src='/images/auo (2).png' alt="sym" style="width:100px; height:100px; object-fit:cover;"></div></div>
<div class='paper-box-text' markdown="1">

AUO, Suzhou

Software Development Intern, NUVA Platform Development Department 

*2024.06 - 2024.08*

</div>
</div>
